>[!Cite] [1]

W. Liu, B. Luo, e J. Liu, “Synthetic Data Augmentation Using Multiscale Attention CycleGAN for Aircraft Detection in Remote Sensing Images”, _IEEE Geosci. Remote Sensing Lett._, vol. 19, p. 1–5, 2022, doi: [10.1109/LGRS.2021.3052017](https://doi.org/10.1109/LGRS.2021.3052017).

>[!Synthesize]
>**Contribution**::

>[!Metadata]
> **Author**:: Liu, Weixing</br> **Author**:: Luo, Bin</br> **Author**:: Liu, Jun</br>
>**Title**:: Synthetic Data Augmentation Using Multiscale Attention CycleGAN for Aircraft Detection in Remote Sensing Images
>**Year**:: 2022
>**Citekey**:: @liuSyntheticDataAugmentation2022
>**itemType**:: journalArticle
>**Journal**:: *IEEE Geoscience and Remote Sensing Letters*
>**Volume**:: 19
>
>
>
>
> **Pages**:: 1-5
>**DOI**:: 10.1109/LGRS.2021.3052017
>

>[!LINK]
>
>[Liu et al. - 2022 - Synthetic Data Augmentation Using Multiscale Atten.pdf](file://C:\Users\maila\Zotero\storage\6FS4RS5U\Liu%20et%20al.%20-%202022%20-%20Synthetic%20Data%20Augmentation%20Using%20Multiscale%20Atten.pdf).

>[!Abstract]
Deep learning approaches require enough training samples to perform well, but it is a challenge to collect enough real training data and label them manually. In this letter, we propose a practical framework for automatically generating content-rich synthetic images with ground-truth annotations. By rendering 3-D CAD models, we generate two synthetic aircraft image data sets with wide distribution (Syn N and Syn U). For improving the quality of synthetic images, we propose a multiscale attention module which enhances the Cycle-Consistent Adversarial Network (CycleGAN) in spatial and channel dimensions. Then, we compare the synthetic images before and after translation qualitatively and quantitatively. Experiments on Northwestern Polytechnical University (NWPU) very high resolution (VHR)-10, University of Chinese Academy of Sciences, orientation robust object detection in aerial images (UCASAOD), and benchmark for object DetectIon in Optical Remote sensing images (DIOR) data sets demonstrate that synthetic data augmentation can improve the performance of aircraft detection in remote sensing images, especially when real data are insufﬁcient. Synthetic data are available at: https://weix-liu. github.io/.

> [!important]
## Annotations

%% begin annotations %%

### Exported: 2024-05-19 19:10
>[!Note]
><mark style="background-color: #5fb236">Highlight</mark></br></br>> DetectIon in Optical Remote sensing images (DIOR) data sets demonstrate that synthetic data augmentation can improve the performance of aircraft detection in remote sensing images, especially when real data are insufficient. Synthetic data are available at: https://weix-liu. github.io/
>>- Conclusão
>[page 1](file://C:\Users\maila\Zotero\storage\6FS4RS5U\Liu%20et%20al.%20-%202022%20-%20Synthetic%20Data%20Augmentation%20Using%20Multiscale%20Atten.pdf) [[2024-05-19 19:05]]

>[!Note]
><mark style="background-color: #2ea8e5">Highlight</mark></br></br>> The proposed approach is realized in two stages. First, 3-D CAD models are collected and a virtual scene is built. Largescale synthetic images with ground-truth bounding boxes are then generated based on DR. Second, synthetic images will be translated from the synthetic domain to the real domain by MSA-CycleGAN
>[page 2](file://C:\Users\maila\Zotero\storage\6FS4RS5U\Liu%20et%20al.%20-%202022%20-%20Synthetic%20Data%20Augmentation%20Using%20Multiscale%20Atten.pdf) [[2024-05-19 19:06]]

>[!Note]
><mark style="background-color: #ff6666">Highlight</mark></br></br>> NWPU VHR-10
>[page 3](file://C:\Users\maila\Zotero\storage\6FS4RS5U\Liu%20et%20al.%20-%202022%20-%20Synthetic%20Data%20Augmentation%20Using%20Multiscale%20Atten.pdf) [[2024-05-19 19:08]]

>[!Note]
><mark style="background-color: #ff6666">Highlight</mark></br></br>> UCAS-AOD
>[page 3](file://C:\Users\maila\Zotero\storage\6FS4RS5U\Liu%20et%20al.%20-%202022%20-%20Synthetic%20Data%20Augmentation%20Using%20Multiscale%20Atten.pdf) [[2024-05-19 19:08]]

>[!Note]
><mark style="background-color: #ff6666">Highlight</mark></br></br>> DIOR
>[page 3](file://C:\Users\maila\Zotero\storage\6FS4RS5U\Liu%20et%20al.%20-%202022%20-%20Synthetic%20Data%20Augmentation%20Using%20Multiscale%20Atten.pdf) [[2024-05-19 19:08]]

>[!Note]
><mark style="background-color: #2ea8e5">Highlight</mark></br></br>> CycleGAN and MSA-CycleGAN
>[page 3](file://C:\Users\maila\Zotero\storage\6FS4RS5U\Liu%20et%20al.%20-%202022%20-%20Synthetic%20Data%20Augmentation%20Using%20Multiscale%20Atten.pdf) [[2024-05-19 19:08]]

>[!Note]
><mark style="background-color: #2ea8e5">Highlight</mark></br></br>> Faster R-CNN and R-FCN: The object detection code was based on the TensorFlow Object Detection air position indicator (API).3 Resnet-101 pretrained on ImageNet was used as the feature extractor
>[page 3](file://C:\Users\maila\Zotero\storage\6FS4RS5U\Liu%20et%20al.%20-%202022%20-%20Synthetic%20Data%20Augmentation%20Using%20Multiscale%20Atten.pdf) [[2024-05-19 19:08]]

>[!Note]
><mark style="background-color: #2ea8e5">Highlight</mark></br></br>> average precision (AP) at 0.75 and mean AP (mAP)
>[page 3](file://C:\Users\maila\Zotero\storage\6FS4RS5U\Liu%20et%20al.%20-%202022%20-%20Synthetic%20Data%20Augmentation%20Using%20Multiscale%20Atten.pdf) [[2024-05-19 19:09]]

>[!Note]
></br></br>
>![[sources/images/liuSyntheticDataAugmentation2022/image-5-x36-y369.png]]
>[page 5](file://C:\Users\maila\Zotero\storage\6FS4RS5U\Liu%20et%20al.%20-%202022%20-%20Synthetic%20Data%20Augmentation%20Using%20Multiscale%20Atten.pdf) [[2024-05-19 19:10]]

%% end annotations %%

%% Import Date: 2024-05-19T19:10:37.517-03:00 %%
